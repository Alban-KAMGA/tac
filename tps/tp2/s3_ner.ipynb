{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance d'entités nommées avec SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentation est accessible ici: https://spacy.io/api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.8.0/fr_core_news_md-3.8.0-py3-none-any.whl (45.8 MB)\n",
      "     ---------------------------------------- 0.0/45.8 MB ? eta -:--:--\n",
      "     - -------------------------------------- 1.3/45.8 MB 6.7 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 2.9/45.8 MB 6.7 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 4.2/45.8 MB 6.6 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 5.2/45.8 MB 6.2 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 6.6/45.8 MB 6.0 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 8.4/45.8 MB 6.5 MB/s eta 0:00:06\n",
      "     -------- ------------------------------- 10.2/45.8 MB 6.6 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 11.8/45.8 MB 6.7 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 13.4/45.8 MB 6.7 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 14.7/45.8 MB 6.6 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 16.3/45.8 MB 6.7 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 17.0/45.8 MB 6.7 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 18.4/45.8 MB 6.4 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 19.9/45.8 MB 6.5 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 21.5/45.8 MB 6.5 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 22.5/45.8 MB 6.5 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 23.3/45.8 MB 6.3 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 24.4/45.8 MB 6.2 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 26.0/45.8 MB 6.2 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 27.0/45.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 28.0/45.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 28.6/45.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 29.6/45.8 MB 5.9 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 30.9/45.8 MB 5.8 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 32.0/45.8 MB 5.8 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 33.0/45.8 MB 5.8 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 34.1/45.8 MB 5.8 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 35.7/45.8 MB 5.8 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 37.0/45.8 MB 5.8 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 38.3/45.8 MB 5.8 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 39.3/45.8 MB 5.8 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 39.8/45.8 MB 5.7 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 40.9/45.8 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 41.9/45.8 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 43.0/45.8 MB 5.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 43.8/45.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  45.1/45.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  45.6/45.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  45.6/45.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  45.6/45.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  45.6/45.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  45.6/45.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  45.6/45.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  45.6/45.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 45.8/45.8 MB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: fr-core-news-md\n",
      "Successfully installed fr-core-news-md-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences\n",
    "!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple sur un corpus de test fourni par SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars',\n",
       " \"Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs\",\n",
       " \"San Francisco envisage d'interdire les robots coursiers sur les trottoirs\",\n",
       " 'Londres est une grande ville du Royaume-Uni',\n",
       " 'L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe',\n",
       " \"Apple lance HomePod parce qu'il se sent menacé par l'Echo d'Amazon\",\n",
       " \"La France ne devrait pas manquer d'électricité cet été, même en cas de canicule\",\n",
       " 'Nouvelles attaques de Trump contre le maire de Londres',\n",
       " 'Où es-tu ?',\n",
       " 'Qui est le président de la France ?',\n",
       " 'Où est la capitale des États-Unis ?',\n",
       " 'Quand est né Barack Obama ?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimer le corpus de Spacy\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isoler la première phrase\n",
    "sent = sentences[0]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traiter la phrase avec Spacy\n",
    "doc = nlp(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars',\n",
       " 'ents': [{'start': 0, 'end': 5, 'label': 'ORG'}],\n",
       " 'sents': [{'start': 0, 'end': 72}],\n",
       " 'tokens': [{'id': 0,\n",
       "   'start': 0,\n",
       "   'end': 5,\n",
       "   'tag': 'PROPN',\n",
       "   'pos': 'PROPN',\n",
       "   'morph': 'Gender=Masc|Number=Sing',\n",
       "   'lemma': 'Apple',\n",
       "   'dep': 'nsubj',\n",
       "   'head': 1},\n",
       "  {'id': 1,\n",
       "   'start': 6,\n",
       "   'end': 13,\n",
       "   'tag': 'VERB',\n",
       "   'pos': 'VERB',\n",
       "   'morph': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin',\n",
       "   'lemma': 'cherche',\n",
       "   'dep': 'ROOT',\n",
       "   'head': 1},\n",
       "  {'id': 2,\n",
       "   'start': 14,\n",
       "   'end': 15,\n",
       "   'tag': 'ADP',\n",
       "   'pos': 'ADP',\n",
       "   'morph': '',\n",
       "   'lemma': 'à',\n",
       "   'dep': 'mark',\n",
       "   'head': 3},\n",
       "  {'id': 3,\n",
       "   'start': 16,\n",
       "   'end': 23,\n",
       "   'tag': 'VERB',\n",
       "   'pos': 'VERB',\n",
       "   'morph': 'VerbForm=Inf',\n",
       "   'lemma': 'acheter',\n",
       "   'dep': 'xcomp',\n",
       "   'head': 1},\n",
       "  {'id': 4,\n",
       "   'start': 24,\n",
       "   'end': 27,\n",
       "   'tag': 'DET',\n",
       "   'pos': 'DET',\n",
       "   'morph': 'Definite=Ind|Gender=Fem|Number=Sing|PronType=Art',\n",
       "   'lemma': 'un',\n",
       "   'dep': 'det',\n",
       "   'head': 5},\n",
       "  {'id': 5,\n",
       "   'start': 28,\n",
       "   'end': 33,\n",
       "   'tag': 'NOUN',\n",
       "   'pos': 'NOUN',\n",
       "   'morph': 'Gender=Fem|Number=Sing',\n",
       "   'lemma': 'start',\n",
       "   'dep': 'obj',\n",
       "   'head': 3},\n",
       "  {'id': 6,\n",
       "   'start': 33,\n",
       "   'end': 34,\n",
       "   'tag': 'PROPN',\n",
       "   'pos': 'PROPN',\n",
       "   'morph': '',\n",
       "   'lemma': '-',\n",
       "   'dep': 'obl:arg',\n",
       "   'head': 3},\n",
       "  {'id': 7,\n",
       "   'start': 34,\n",
       "   'end': 36,\n",
       "   'tag': 'X',\n",
       "   'pos': 'X',\n",
       "   'morph': '',\n",
       "   'lemma': 'up',\n",
       "   'dep': 'obl:arg',\n",
       "   'head': 3},\n",
       "  {'id': 8,\n",
       "   'start': 37,\n",
       "   'end': 45,\n",
       "   'tag': 'ADJ',\n",
       "   'pos': 'ADJ',\n",
       "   'morph': 'Gender=Fem|Number=Sing',\n",
       "   'lemma': 'anglais',\n",
       "   'dep': 'obj',\n",
       "   'head': 3},\n",
       "  {'id': 9,\n",
       "   'start': 46,\n",
       "   'end': 50,\n",
       "   'tag': 'ADP',\n",
       "   'pos': 'ADP',\n",
       "   'morph': '',\n",
       "   'lemma': 'pour',\n",
       "   'dep': 'case',\n",
       "   'head': 11},\n",
       "  {'id': 10,\n",
       "   'start': 51,\n",
       "   'end': 52,\n",
       "   'tag': 'NUM',\n",
       "   'pos': 'NUM',\n",
       "   'morph': 'NumType=Card',\n",
       "   'lemma': '1',\n",
       "   'dep': 'nummod',\n",
       "   'head': 11},\n",
       "  {'id': 11,\n",
       "   'start': 53,\n",
       "   'end': 61,\n",
       "   'tag': 'NOUN',\n",
       "   'pos': 'NOUN',\n",
       "   'morph': 'Gender=Masc|NumType=Card|Number=Sing',\n",
       "   'lemma': 'milliard',\n",
       "   'dep': 'obl:mod',\n",
       "   'head': 3},\n",
       "  {'id': 12,\n",
       "   'start': 62,\n",
       "   'end': 64,\n",
       "   'tag': 'ADP',\n",
       "   'pos': 'ADP',\n",
       "   'morph': '',\n",
       "   'lemma': 'de',\n",
       "   'dep': 'case',\n",
       "   'head': 13},\n",
       "  {'id': 13,\n",
       "   'start': 65,\n",
       "   'end': 72,\n",
       "   'tag': 'NOUN',\n",
       "   'pos': 'NOUN',\n",
       "   'morph': 'Gender=Masc|Number=Plur',\n",
       "   'lemma': 'dollar',\n",
       "   'dep': 'nmod',\n",
       "   'head': 11}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars' contient les entités suivantes : Apple (ORG)\n",
      "'Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs' ne contient aucune entité\n",
      "'San Francisco envisage d'interdire les robots coursiers sur les trottoirs' contient les entités suivantes : San Francisco (LOC)\n",
      "'Londres est une grande ville du Royaume-Uni' contient les entités suivantes : Londres (LOC), Royaume-Uni (LOC)\n",
      "'L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe' contient les entités suivantes : L’Italie (LOC), ArcelorMittal (ORG), Europe (LOC)\n",
      "'Apple lance HomePod parce qu'il se sent menacé par l'Echo d'Amazon' contient les entités suivantes : Apple (ORG), HomePod (MISC), Echo (ORG), Amazon (ORG)\n",
      "'La France ne devrait pas manquer d'électricité cet été, même en cas de canicule' contient les entités suivantes : La France (LOC)\n",
      "'Nouvelles attaques de Trump contre le maire de Londres' contient les entités suivantes : Nouvelles attaques de (MISC), Trump (PER), Londres (LOC)\n",
      "'Où es-tu ?' ne contient aucune entité\n",
      "'Qui est le président de la France ?' contient les entités suivantes : la France (LOC)\n",
      "'Où est la capitale des États-Unis ?' contient les entités suivantes : États-Unis (LOC)\n",
      "'Quand est né Barack Obama ?' contient les entités suivantes : Barack Obama (PER)\n"
     ]
    }
   ],
   "source": [
    "# Appliquer le test sur toutes les phrases\n",
    "for sent in sentences:\n",
    "    doc = nlp(sent)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append(f\"{ent.text} ({ent.label_})\")\n",
    "    if entities:\n",
    "        print(f\"'{doc.text}' contient les entités suivantes : {', '.join(entities)}\")\n",
    "    else:\n",
    "        print(f\"'{doc.text}' ne contient aucune entité\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appliquer la reconnaissance d'entités nommées sur notre corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le texte\n",
    "n=1000000\n",
    "text = open(\"../data/all.txt\", encoding='utf-8').read()[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 28s\n",
      "Wall time: 7min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Traiter le texte\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les entités\n",
    "people = defaultdict(int)\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\" and len(ent.text) > 3:\n",
    "        people[ent.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messieurs apparait 30 fois dans le corpus\n",
      "Verger apparait 12 fois dans le corpus\n",
      "Pape apparait 10 fois dans le corpus\n",
      "Créd apparait 9 fois dans le corpus\n",
      "Verhaegen apparait 7 fois dans le corpus\n",
      "Belg apparait 7 fois dans le corpus\n",
      "M. Malou apparait 6 fois dans le corpus\n",
      "Holl apparait 6 fois dans le corpus\n",
      "Van Zeeland apparait 6 fois dans le corpus\n",
      "Robert apparait 5 fois dans le corpus\n",
      "Lebrun apparait 5 fois dans le corpus\n",
      "M. Genay apparait 5 fois dans le corpus\n",
      "Lundi apparait 4 fois dans le corpus\n",
      "Tisza apparait 4 fois dans le corpus\n",
      "Mme Loubet apparait 4 fois dans le corpus\n",
      "Monsieur apparait 4 fois dans le corpus\n",
      "Président apparait 4 fois dans le corpus\n",
      "Mme de Sermaize apparait 4 fois dans le corpus\n",
      "M. Van apparait 4 fois dans le corpus\n",
      "Arcy apparait 4 fois dans le corpus\n",
      "Adieu apparait 4 fois dans le corpus\n",
      "Thaddée apparait 4 fois dans le corpus\n",
      "Armand apparait 4 fois dans le corpus\n",
      "Mgr Lecouvet apparait 4 fois dans le corpus\n",
      "Staline apparait 4 fois dans le corpus\n",
      "Lord Lloyd apparait 4 fois dans le corpus\n",
      "Daladier apparait 4 fois dans le corpus\n",
      "M. Gouin apparait 4 fois dans le corpus\n",
      "faul apparait 4 fois dans le corpus\n",
      "Bellevue apparait 4 fois dans le corpus\n",
      "Moyes apparait 4 fois dans le corpus\n",
      "Parée J. apparait 4 fois dans le corpus\n",
      "Jambon apparait 3 fois dans le corpus\n",
      "franco apparait 3 fois dans le corpus\n",
      "catholi apparait 3 fois dans le corpus\n",
      "Temps apparait 3 fois dans le corpus\n",
      "Kayser apparait 3 fois dans le corpus\n",
      "Léopold apparait 3 fois dans le corpus\n",
      "Costa apparait 3 fois dans le corpus\n",
      "M. Sabatier apparait 3 fois dans le corpus\n",
      "M. Doppfer apparait 3 fois dans le corpus\n",
      "Albert apparait 3 fois dans le corpus\n",
      "Autr apparait 3 fois dans le corpus\n",
      "prince Léopold apparait 3 fois dans le corpus\n",
      "Astrid apparait 3 fois dans le corpus\n",
      "Pie XI apparait 3 fois dans le corpus\n",
      "Charton apparait 3 fois dans le corpus\n",
      "Nollet apparait 3 fois dans le corpus\n",
      "Célestes apparait 3 fois dans le corpus\n",
      "Josée Goffin apparait 3 fois dans le corpus\n"
     ]
    }
   ],
   "source": [
    "# Trier et imprimer\n",
    "\n",
    "sorted_people = sorted(people.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "for person, freq in sorted_people[:50]:\n",
    "    print(f\"{person} apparait {freq} fois dans le corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice: essayez de lister les lieux (LOC) et les organisations (ORG) les plus mentionnées dans le corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
